{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930152cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 18:18:33.574404: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-09-22 18:18:33.574462: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_unixtime, hour, when\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df1e981",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"DataModeling\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2746ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read the Parquet file into a DataFrame\n",
    "df = spark.read.parquet(\"/user1/data/parquet/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b67820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------+-------------------------+-------------------+------------------+-------------------+------------------+\n",
      "|square_id|timestamp          |country_code|internet_traffic_activity|hourly_timestamp   |SMS_activity      |call_activity      |weekend_or_weekday|\n",
      "+---------+-------------------+------------+-------------------------+-------------------+------------------+-------------------+------------------+\n",
      "|1        |2013-10-31 23:00:00|39          |11.028366381681026       |2013-10-31 23:00:00|0.2986512597414538|0.2132127854455914 |weekday           |\n",
      "|1        |2013-10-31 23:10:00|39          |11.100963451409388       |2013-10-31 23:00:00|0.3983777976024016|0.32241464495433614|weekday           |\n",
      "+---------+-------------------+------------+-------------------------+-------------------+------------------+-------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(2, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bb2d771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- square_id: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- country_code: integer (nullable = true)\n",
      " |-- internet_traffic_activity: double (nullable = true)\n",
      " |-- hourly_timestamp: string (nullable = true)\n",
      " |-- SMS_activity: double (nullable = true)\n",
      " |-- call_activity: double (nullable = true)\n",
      " |-- weekend_or_weekday: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c300a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7516761"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef650868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=================================================>         (5 + 1) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of distinct rows: 7516761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print('Count of distinct rows: {0}'.format(df.distinct().count())) #duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "633fca15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|country_code|  count|\n",
      "+------------+-------+\n",
      "|          45|      1|\n",
      "|          40|      1|\n",
      "|         966|      2|\n",
      "|         421|      2|\n",
      "|         353|      3|\n",
      "|         385|      3|\n",
      "|          61|      4|\n",
      "|          31|      4|\n",
      "|         356|      5|\n",
      "|          90|      6|\n",
      "|         386|      7|\n",
      "|         351|      9|\n",
      "|          43|     14|\n",
      "|          32|     15|\n",
      "|         358|     21|\n",
      "|           0|     21|\n",
      "|         213|     23|\n",
      "|          47|     42|\n",
      "|          34|     68|\n",
      "|           1|     91|\n",
      "|         420|     93|\n",
      "|          48|     98|\n",
      "|          49|    151|\n",
      "|          46|    218|\n",
      "|           7|    496|\n",
      "|          86|   1054|\n",
      "|          44|   1197|\n",
      "|          33|   1298|\n",
      "|          41|   1353|\n",
      "|          39|7510461|\n",
      "+------------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.groupby('country_code').count().sort('count').show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c74e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------+--------------------+--------------------+\n",
      "|summary|internet_traffic_activity|        SMS_activity|       call_activity|\n",
      "+-------+-------------------------+--------------------+--------------------+\n",
      "|  count|                  7516761|             7516761|             7516761|\n",
      "|   mean|        81.02824368179743|   7.151377454212734|    8.21545912479918|\n",
      "| stddev|       143.69671563945369|  14.738696897264143|  16.946580289458204|\n",
      "|    min|     4.792346910579604E-5|1.235047397115846...|4.662995399058662E-6|\n",
      "|    max|        7936.265379884158|   1211.443277333027|   532.5074148119132|\n",
      "+-------+-------------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# numerical stat\n",
    "df.describe(['internet_traffic_activity', 'SMS_activity', 'call_activity']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93ceef24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn(\"square_id\", col(\"square_id\").cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d7ea3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1.0, 0.1415706480958958, 0.12647822181687138, 0.12565426847843997],\n",
       " [None, 1.0, 0.8789476193973431, 0.8444776822637831],\n",
       " [None, None, 1.0, 0.8929825876389413],\n",
       " [None, None, None, 1.0]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correlation\n",
    "features = ['square_id', 'internet_traffic_activity', 'SMS_activity', 'call_activity']\n",
    "n = len(features)\n",
    "\n",
    "corr = []\n",
    "\n",
    "for i in range(0, n):\n",
    "    temp = [None]*i\n",
    "    \n",
    "    for j in range(i, n):\n",
    "        temp.append(df.corr(features[i], features[j]))\n",
    "    corr.append(temp)\n",
    "    \n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30404494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 27:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------+-------------------------+-------------------+--------------------+--------------------+------------------+-----------+-----------+\n",
      "|square_id|          timestamp|country_code|internet_traffic_activity|   hourly_timestamp|        SMS_activity|       call_activity|weekend_or_weekday|hour_of_day|time_of_day|\n",
      "+---------+-------------------+------------+-------------------------+-------------------+--------------------+--------------------+------------------+-----------+-----------+\n",
      "|        1|2013-10-31 23:00:00|          39|       11.028366381681026|2013-10-31 23:00:00|  0.2986512597414538|  0.2132127854455914|           weekday|         23|      night|\n",
      "|        1|2013-10-31 23:10:00|          39|       11.100963451409388|2013-10-31 23:00:00|  0.3983777976024016| 0.32241464495433614|           weekday|         23|      night|\n",
      "|        1|2013-10-31 23:20:00|          39|       10.892770602791096|2013-10-31 23:00:00|  0.5015934573020482|  0.1887771729145041|           weekday|         23|      night|\n",
      "|        1|2013-10-31 23:30:00|          39|        8.622424590989748|2013-10-31 23:00:00|  0.9022493783046439| 0.08073835401865896|           weekday|         23|      night|\n",
      "|        1|2013-10-31 23:40:00|          39|        8.009927462445756|2013-10-31 23:00:00| 0.43626866691467914| 0.13417624316013174|           weekday|         23|      night|\n",
      "|        1|2013-10-31 23:50:00|          39|          8.1184195540896|2013-10-31 23:00:00|  0.2997663425287483| 0.05460092975437236|           weekday|         23|      night|\n",
      "|        1|2013-11-01 00:00:00|          39|        8.026269748512151|2013-11-01 00:00:00| 0.22027652749528903|0.055225199246972216|           weekend|          0|      night|\n",
      "|        1|2013-11-01 00:10:00|          39|        8.514178577183893|2013-11-01 00:00:00| 0.21491459717879072|  0.0563882398598718|           weekend|          0|      night|\n",
      "|        1|2013-11-01 00:20:00|          39|       6.8334248963840505|2013-11-01 00:00:00|  0.4025287294803952| 0.13417624316013174|           weekend|          0|      night|\n",
      "|        1|2013-11-01 00:30:00|          39|         6.55460504454769|2013-11-01 00:00:00|  0.5401940944792257| 0.10803881889584514|           weekend|          0|      night|\n",
      "|        1|2013-11-01 04:00:00|          39|        6.085673982439326|2013-11-01 04:00:00| 0.05406215863407264|0.052274848528573205|           weekend|          4|      night|\n",
      "|        1|2013-11-01 05:50:00|          39|        5.957483939088293|2013-11-01 05:00:00| 0.10571273767004599| 0.10454969705714641|           weekend|          5|      night|\n",
      "|        1|2013-11-01 06:00:00|          39|        6.640460593426143|2013-11-01 06:00:00| 0.14016244296922992| 0.13417624316013174|           weekday|          6|    morning|\n",
      "|        1|2013-11-01 06:10:00|          39|       7.0092000852653635|2013-11-01 06:00:00|0.029087774982685617| 0.15977489630411862|           weekday|          6|    morning|\n",
      "|        1|2013-11-01 06:20:00|          39|        6.160143860645488|2013-11-01 06:00:00| 0.13658782275823106| 0.08314993361675826|           weekday|          6|    morning|\n",
      "|        1|2013-11-01 06:30:00|          39|         7.79788947727326|2013-11-01 06:00:00| 0.19413910323100242| 0.11161343910684401|           weekday|          6|    morning|\n",
      "|        1|2013-11-01 06:40:00|          39|        7.309884732950306|2013-11-01 06:00:00|  0.1894869407794041| 0.14007694459692976|           weekday|          6|    morning|\n",
      "|        1|2013-11-01 06:50:00|          39|         8.01592542191505|2013-11-01 06:00:00| 0.13658782275823106| 0.10928735788104485|           weekday|          6|    morning|\n",
      "|        1|2013-11-01 07:00:00|          39|        9.431191468740728|2013-11-01 07:00:00|  0.6959890556499511| 0.18591232056840523|           weekday|          7|    morning|\n",
      "|        1|2013-11-01 07:10:00|          39|         9.08251636060311|2013-11-01 07:00:00| 0.21621109398959554|   0.400826917747196|           weekday|          7|    morning|\n",
      "+---------+-------------------+------------+-------------------------+-------------------+--------------------+--------------------+------------------+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# transform timestamp into categorical values\n",
    "from pyspark.sql.functions import hour\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "df = df.withColumn('hour_of_day', hour(df.timestamp))\n",
    "\n",
    "def categorize_hour(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return 'morning'\n",
    "    elif 12 <= hour < 15:\n",
    "        return 'lunch'\n",
    "    elif 15 <= hour < 18:\n",
    "        return 'afternoon'\n",
    "    elif 18 <= hour < 22:\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "    \n",
    "# Apply the UDF to create a new column with categorical values\n",
    "categorize_hour_udf = udf(categorize_hour)\n",
    "df = df.withColumn('time_of_day', categorize_hour_udf(df.hour_of_day))\n",
    "\n",
    "# Show the transformed DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "693d6096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group the data by time_of_day and aggregate the average of each activity\n",
    "activity_by_time_of_day = df.groupBy('time_of_day').agg({'SMS_activity': 'avg', 'call_activity': 'avg', 'internet_traffic_activity': 'avg'})\n",
    "\n",
    "# Convert the DataFrame to a Pandas DataFrame for plotting\n",
    "activity_by_time_of_day_pd = activity_by_time_of_day.toPandas()\n",
    "\n",
    "# Plot the average volume of each activity per time_of_day\n",
    "activity_by_time_of_day_pd.plot(kind='bar', x='time_of_day', y=['avg(SMS_activity)', 'avg(call_activity)', 'avg(internet_traffic_activity)'])\n",
    "plt.title('Avg volume of SMS, call and internet activity across the day')\n",
    "plt.xlabel('Time of Day')\n",
    "plt.ylabel('Average Volume')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e59ade3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+------------+-------------------------+-------------------+--------------------+--------------------+------------------+-----------+-----------+------------------------+-----------------+--------------------------+-------------------+\n",
      "|square_id|          timestamp|country_code|internet_traffic_activity|   hourly_timestamp|        SMS_activity|       call_activity|weekend_or_weekday|hour_of_day|time_of_day|weekend_or_weekday_index|time_of_day_index|weekend_or_weekday_encoded|time_of_day_encoded|\n",
      "+---------+-------------------+------------+-------------------------+-------------------+--------------------+--------------------+------------------+-----------+-----------+------------------------+-----------------+--------------------------+-------------------+\n",
      "|        1|2013-10-31 23:00:00|          39|       11.028366381681026|2013-10-31 23:00:00|  0.2986512597414538|  0.2132127854455914|           weekday|         23|      night|                     0.0|              4.0|             (1,[0],[1.0])|          (4,[],[])|\n",
      "|        1|2013-10-31 23:10:00|          39|       11.100963451409388|2013-10-31 23:00:00|  0.3983777976024016| 0.32241464495433614|           weekday|         23|      night|                     0.0|              4.0|             (1,[0],[1.0])|          (4,[],[])|\n",
      "|        1|2013-10-31 23:20:00|          39|       10.892770602791096|2013-10-31 23:00:00|  0.5015934573020482|  0.1887771729145041|           weekday|         23|      night|                     0.0|              4.0|             (1,[0],[1.0])|          (4,[],[])|\n",
      "|        1|2013-10-31 23:30:00|          39|        8.622424590989748|2013-10-31 23:00:00|  0.9022493783046439| 0.08073835401865896|           weekday|         23|      night|                     0.0|              4.0|             (1,[0],[1.0])|          (4,[],[])|\n",
      "|        1|2013-10-31 23:40:00|          39|        8.009927462445756|2013-10-31 23:00:00| 0.43626866691467914| 0.13417624316013174|           weekday|         23|      night|                     0.0|              4.0|             (1,[0],[1.0])|          (4,[],[])|\n",
      "|        1|2013-10-31 23:50:00|          39|          8.1184195540896|2013-10-31 23:00:00|  0.2997663425287483| 0.05460092975437236|           weekday|         23|      night|                     0.0|              4.0|             (1,[0],[1.0])|          (4,[],[])|\n",
      "|        1|2013-11-01 00:00:00|          39|        8.026269748512151|2013-11-01 00:00:00| 0.22027652749528903|0.055225199246972216|           weekend|          0|      night|                     1.0|              4.0|                 (1,[],[])|          (4,[],[])|\n",
      "|        1|2013-11-01 00:10:00|          39|        8.514178577183893|2013-11-01 00:00:00| 0.21491459717879072|  0.0563882398598718|           weekend|          0|      night|                     1.0|              4.0|                 (1,[],[])|          (4,[],[])|\n",
      "|        1|2013-11-01 00:20:00|          39|       6.8334248963840505|2013-11-01 00:00:00|  0.4025287294803952| 0.13417624316013174|           weekend|          0|      night|                     1.0|              4.0|                 (1,[],[])|          (4,[],[])|\n",
      "|        1|2013-11-01 00:30:00|          39|         6.55460504454769|2013-11-01 00:00:00|  0.5401940944792257| 0.10803881889584514|           weekend|          0|      night|                     1.0|              4.0|                 (1,[],[])|          (4,[],[])|\n",
      "|        1|2013-11-01 04:00:00|          39|        6.085673982439326|2013-11-01 04:00:00| 0.05406215863407264|0.052274848528573205|           weekend|          4|      night|                     1.0|              4.0|                 (1,[],[])|          (4,[],[])|\n",
      "|        1|2013-11-01 05:50:00|          39|        5.957483939088293|2013-11-01 05:00:00| 0.10571273767004599| 0.10454969705714641|           weekend|          5|      night|                     1.0|              4.0|                 (1,[],[])|          (4,[],[])|\n",
      "|        1|2013-11-01 06:00:00|          39|        6.640460593426143|2013-11-01 06:00:00| 0.14016244296922992| 0.13417624316013174|           weekday|          6|    morning|                     0.0|              0.0|             (1,[0],[1.0])|      (4,[0],[1.0])|\n",
      "|        1|2013-11-01 06:10:00|          39|       7.0092000852653635|2013-11-01 06:00:00|0.029087774982685617| 0.15977489630411862|           weekday|          6|    morning|                     0.0|              0.0|             (1,[0],[1.0])|      (4,[0],[1.0])|\n",
      "|        1|2013-11-01 06:20:00|          39|        6.160143860645488|2013-11-01 06:00:00| 0.13658782275823106| 0.08314993361675826|           weekday|          6|    morning|                     0.0|              0.0|             (1,[0],[1.0])|      (4,[0],[1.0])|\n",
      "|        1|2013-11-01 06:30:00|          39|         7.79788947727326|2013-11-01 06:00:00| 0.19413910323100242| 0.11161343910684401|           weekday|          6|    morning|                     0.0|              0.0|             (1,[0],[1.0])|      (4,[0],[1.0])|\n",
      "|        1|2013-11-01 06:40:00|          39|        7.309884732950306|2013-11-01 06:00:00|  0.1894869407794041| 0.14007694459692976|           weekday|          6|    morning|                     0.0|              0.0|             (1,[0],[1.0])|      (4,[0],[1.0])|\n",
      "|        1|2013-11-01 06:50:00|          39|         8.01592542191505|2013-11-01 06:00:00| 0.13658782275823106| 0.10928735788104485|           weekday|          6|    morning|                     0.0|              0.0|             (1,[0],[1.0])|      (4,[0],[1.0])|\n",
      "|        1|2013-11-01 07:00:00|          39|        9.431191468740728|2013-11-01 07:00:00|  0.6959890556499511| 0.18591232056840523|           weekday|          7|    morning|                     0.0|              0.0|             (1,[0],[1.0])|      (4,[0],[1.0])|\n",
      "|        1|2013-11-01 07:10:00|          39|         9.08251636060311|2013-11-01 07:00:00| 0.21621109398959554|   0.400826917747196|           weekday|          7|    morning|                     0.0|              0.0|             (1,[0],[1.0])|      (4,[0],[1.0])|\n",
      "+---------+-------------------+------------+-------------------------+-------------------+--------------------+--------------------+------------------+-----------+-----------+------------------------+-----------------+--------------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#preparing for modeling (cat values, scaling, splitting)\n",
    "# handle categorical values\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer,OneHotEncoder\n",
    "\n",
    "indexer1 = StringIndexer(inputCol='weekend_or_weekday', outputCol='weekend_or_weekday_index')\n",
    "indexed1 = indexer1.fit(df).transform(df)\n",
    "\n",
    "indexer2 = StringIndexer(inputCol='time_of_day', outputCol='time_of_day_index')\n",
    "indexed2 = indexer2.fit(indexed1).transform(indexed1)\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=['weekend_or_weekday_index', 'time_of_day_index'], outputCols=['weekend_or_weekday_encoded', 'time_of_day_encoded'])\n",
    "encoded = encoder.fit(indexed2).transform(indexed2)\n",
    "\n",
    "encoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f635171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- square_id: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- country_code: integer (nullable = true)\n",
      " |-- internet_traffic_activity: double (nullable = true)\n",
      " |-- hourly_timestamp: string (nullable = true)\n",
      " |-- SMS_activity: double (nullable = true)\n",
      " |-- call_activity: double (nullable = true)\n",
      " |-- weekend_or_weekday: string (nullable = true)\n",
      " |-- hour_of_day: integer (nullable = true)\n",
      " |-- time_of_day: string (nullable = true)\n",
      " |-- weekend_or_weekday_index: double (nullable = false)\n",
      " |-- time_of_day_index: double (nullable = false)\n",
      " |-- weekend_or_weekday_encoded: vector (nullable = true)\n",
      " |-- time_of_day_encoded: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dropping values not needed for the model\n",
    "encoded.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50512ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoded.drop('timestamp', 'hour_of_day', 'time_of_day', 'weekend_or_weekday', 'weekend_or_weekday_index', 'time_of_day_index', 'hourly_timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6add4469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- square_id: integer (nullable = true)\n",
      " |-- country_code: integer (nullable = true)\n",
      " |-- internet_traffic_activity: double (nullable = true)\n",
      " |-- SMS_activity: double (nullable = true)\n",
      " |-- call_activity: double (nullable = true)\n",
      " |-- weekend_or_weekday_encoded: vector (nullable = true)\n",
      " |-- time_of_day_encoded: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f30a709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization or scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bca607b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "internet = df.select(['internet_traffic_activity']).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "de701d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hduser/.local/lib/python3.10/site-packages/seaborn/_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "/home/hduser/.local/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(internet['internet_traffic_activity']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "36beccac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The skewness of the 'SMS_activity' column is: 7.866375062955847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import skewness\n",
    "\n",
    "skewness_value = df.agg(skewness('SMS_activity')).collect()[0][0]\n",
    "print(f\"The skewness of the 'SMS_activity' column is: {skewness_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af2dbeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The skewness of the 'call_activity' column is: 6.846711937178775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "skewness_value = df.agg(skewness('call_activity')).collect()[0][0]\n",
    "print(f\"The skewness of the 'call_activity' column is: {skewness_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd5bbc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "36c87551",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=encoded.columns, outputCol=\"features\")\n",
    "output = assembler.transform(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5941e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normalizedFeatures\", p=2.0)\n",
    "normalizedData = normalizer.transform(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "095a6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = normalizedData.select(\"normalizedFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "59b69826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normalizedFeatures']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "93bbe50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: normalize properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2c9882e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for training the autoencoder\n",
    "X_train = encoded.select(\"*\")  # \"*\" to take all input features\n",
    "rdd = X_train.rdd\n",
    "input_dim = len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4e9fceaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-22 19:32:21.231793: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-09-22 19:32:21.231843: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-09-22 19:32:21.240557: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-09-22 19:32:21.257970: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-09-22 19:32:37.350052: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-09-22 19:32:37.351648: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-09-22 19:32:37.353069: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (muhammad-VM): /proc/driver/nvidia/version does not exist\n",
      "2023-09-22 19:32:37.362649: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-22 19:32:37.496748: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-09-22 19:32:37.496785: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-09-22 19:32:37.496816: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (muhammad-VM): /proc/driver/nvidia/version does not exist\n",
      "2023-09-22 19:32:37.497214: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-22 19:32:38,370 ERROR executor.Executor: Exception in task 0.0 in stage 63.0 (TID 77)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n",
      "    process()\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 609, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line 614, in func\n",
      "    rand.shuffle(samples)\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line 934, in func\n",
      "    try:\n",
      "  File \"/tmp/ipykernel_5570/2145153841.py\", line -1, in train_autoencoder\n",
      "  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 790, in __init__\n",
      "    raise ValueError(\"`y` argument is not supported when using \"\n",
      "ValueError: `y` argument is not supported when using python generator as input.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:556)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:762)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:744)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:509)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "2023-09-22 19:32:38,410 ERROR executor.Executor: Exception in task 1.0 in stage 63.0 (TID 78)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n",
      "    process()\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 609, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line 614, in func\n",
      "    rand.shuffle(samples)\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line 934, in func\n",
      "    try:\n",
      "  File \"/tmp/ipykernel_5570/2145153841.py\", line -1, in train_autoencoder\n",
      "  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 790, in __init__\n",
      "    raise ValueError(\"`y` argument is not supported when using \"\n",
      "ValueError: `y` argument is not supported when using python generator as input.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:556)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:762)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:744)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:509)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "2023-09-22 19:32:38,417 WARN scheduler.TaskSetManager: Lost task 0.0 in stage 63.0 (TID 77) (10.0.2.15 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n",
      "    process()\n",
      "  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 609, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line 614, in func\n",
      "    rand.shuffle(samples)\n",
      "  File \"/usr/local/spark/python/pyspark/rdd.py\", line 934, in func\n",
      "    try:\n",
      "  File \"/tmp/ipykernel_5570/2145153841.py\", line -1, in train_autoencoder\n",
      "  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 790, in __init__\n",
      "    raise ValueError(\"`y` argument is not supported when using \"\n",
      "ValueError: `y` argument is not supported when using python generator as input.\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:556)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:762)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:744)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:509)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "2023-09-22 19:32:38,417 ERROR scheduler.TaskSetManager: Task 0 in stage 63.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 63.0 failed 1 times, most recent failure: Lost task 0.0 in stage 63.0 (TID 77) (10.0.2.15 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 609, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 614, in func\n    rand.shuffle(samples)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 934, in func\n    try:\n  File \"/tmp/ipykernel_5570/2145153841.py\", line -1, in train_autoencoder\n  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 790, in __init__\n    raise ValueError(\"`y` argument is not supported when using \"\nValueError: `y` argument is not supported when using python generator as input.\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:556)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:762)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:744)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:509)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2450)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2399)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2398)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2398)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1156)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1156)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1156)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2638)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2580)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2569)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2224)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2245)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2264)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2289)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 609, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 614, in func\n    rand.shuffle(samples)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 934, in func\n    try:\n  File \"/tmp/ipykernel_5570/2145153841.py\", line -1, in train_autoencoder\n  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 790, in __init__\n    raise ValueError(\"`y` argument is not supported when using \"\nValueError: `y` argument is not supported when using python generator as input.\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:556)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:762)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:744)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:509)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5570/2145153841.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Train the autoencoder model on each partition of the RDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeachPartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_autoencoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Detect anomalies using the trained autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mforeachPartition\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Force evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \"\"\"\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;36m6.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \"\"\"\n\u001b[0;32m-> 1226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mfold\u001b[0;34m(self, zeroValue, op)\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \u001b[0;31m# zeroValue provided to each partition is unique from the one provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m         \u001b[0;31m# to the final reduce call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1080\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1081\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeroValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \"\"\"\n\u001b[1;32m    949\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 63.0 failed 1 times, most recent failure: Lost task 0.0 in stage 63.0 (TID 77) (10.0.2.15 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 609, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 614, in func\n    rand.shuffle(samples)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 934, in func\n    try:\n  File \"/tmp/ipykernel_5570/2145153841.py\", line -1, in train_autoencoder\n  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 790, in __init__\n    raise ValueError(\"`y` argument is not supported when using \"\nValueError: `y` argument is not supported when using python generator as input.\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:556)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:762)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:744)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:509)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2450)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2399)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2398)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2398)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1156)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1156)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1156)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2638)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2580)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2569)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2224)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2245)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2264)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2289)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1030)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:414)\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:1029)\n\tat org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:180)\n\tat org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 619, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 609, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line -1, in pipeline_func\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 614, in func\n    rand.shuffle(samples)\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 934, in func\n    try:\n  File \"/tmp/ipykernel_5570/2145153841.py\", line -1, in train_autoencoder\n  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/home/hduser/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 790, in __init__\n    raise ValueError(\"`y` argument is not supported when using \"\nValueError: `y` argument is not supported when using python generator as input.\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:556)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:762)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:744)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:509)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1030)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2264)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:506)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1491)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:509)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "# Define a function to train the autoencoder model on each partition\n",
    "def train_autoencoder(partition):\n",
    "\n",
    "    # Create a new autoencoder model for each partition\n",
    "    autoencoder = Sequential([\n",
    "        Dense(encoding_dim, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(input_dim, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile and fit the autoencoder model on the partition data\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "    autoencoder.fit(partition, partition, epochs=10, batch_size=32)\n",
    "\n",
    "# Train the autoencoder model on each partition of the RDD\n",
    "rdd.foreachPartition(train_autoencoder)\n",
    "\n",
    "# Detect anomalies using the trained autoencoder\n",
    "reconstructed_data = autoencoder.predict(X_train)\n",
    "mse = tf.keras.losses.mean_squared_error(X_train, reconstructed_data)\n",
    "anomaly_threshold = mse.mean() + mse.std() * 2  # Adjust the threshold as per your requirements\n",
    "\n",
    "anomalies = X_train[mse > anomaly_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5443b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
